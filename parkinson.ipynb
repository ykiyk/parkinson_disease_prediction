{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "imports"
      ],
      "metadata": {
        "id": "dbucMlpgDpqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "UjvG_hsGDwMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data set"
      ],
      "metadata": {
        "id": "0EdNpCXLEpny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"parkison_data.csv\")\n",
        "#Target variable from file is status value 1 represents positive, 0 represents negative\n",
        "X=df.drop(columns=[\"name\",\"status\"])\n",
        "Y=df[\"status\"]\n",
        "#training Dataset\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=3)\n",
        "#reducing range of features\n",
        "sc=StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train=sc.transform(X_train)\n",
        "X_test=sc.transform(X_test)\n",
        "#training the data using algo\n",
        "sv=svm.SVC(kernel=\"linear\")\n",
        "sv.fit(X_train,Y_train)\n",
        "\n",
        "X_pred_test=sv.predict(X_test)\n",
        "acc=accuracy_score(Y_test,X_pred_test)\n",
        "print(\"Accuracy of test svm is\",acc)\n",
        "X_pred_train=sv.predict(X_train)\n",
        "acc=accuracy_score(Y_train,X_pred_train)\n",
        "print(\"Accuracy of training in svm is\",acc)\n",
        "conf_matrix = confusion_matrix(Y_test, X_pred_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "YkKy8dPpEswR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49831547-3c77-4271-a97a-fa0e1e1226ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of test svm is 0.9230769230769231\n",
            "Accuracy of training in svm is 0.8782051282051282\n",
            "Confusion Matrix:\n",
            "[[ 6  1]\n",
            " [ 2 30]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, Y_train)\n",
        "DT_test = clf.predict(X_test)\n",
        "accuracy = clf.score(X_test, Y_test)\n",
        "print(\"Accuracy of Decision Tree on test:\", accuracy)\n",
        "X_pred_train=clf.predict(X_train)\n",
        "acc=accuracy_score(Y_train,X_pred_train)\n",
        "print(\"Accuracy of training in clf is\",acc)\n",
        "conf_matrix = confusion_matrix(Y_test, DT_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_ZsuSPDK-1Y",
        "outputId": "4ca1acc3-7d16-4ce2-c1e4-07e03e9b7fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Decision Tree on test: 0.8461538461538461\n",
            "Accuracy of training in clf is 1.0\n",
            "Confusion Matrix:\n",
            "[[ 6  1]\n",
            " [ 5 27]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#random_forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, Y_train)\n",
        "rf_test = rf.predict(X_test)\n",
        "accuracy = rf.score(X_test, Y_test)\n",
        "print(\"Accuracy of random forest on test:\", accuracy)\n",
        "X_pred_train=rf.predict(X_train)\n",
        "acc=accuracy_score(Y_train,X_pred_train)\n",
        "print(\"Accuracy of training in Random forest is\",acc)\n",
        "conf_matrix = confusion_matrix(Y_test, rf_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQqZ--xSSiij",
        "outputId": "f8aa94ee-8556-43d9-8735-b4e18bc26a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of random forest on test: 0.9230769230769231\n",
            "Accuracy of training in Random forest is 1.0\n",
            "Confusion Matrix:\n",
            "[[ 5  2]\n",
            " [ 1 31]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cPGPniMBKxil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN Classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "k = KNeighborsClassifier()\n",
        "k.fit(X_train, Y_train)\n",
        "k_test = k.predict(X_test)\n",
        "accuracy = k.score(X_test, Y_test)\n",
        "print(\"Accuracy of knn on test:\", accuracy)\n",
        "X_pred_train=k.predict(X_train)\n",
        "acc=accuracy_score(Y_train,X_pred_train)\n",
        "print(\"Accuracy of training in KNN is\",acc)\n",
        "conf_matrix = confusion_matrix(Y_test, k_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3TGFR_fTMun",
        "outputId": "0cc80585-e3db-4ef4-d851-58a032232abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of knn on test: 0.8461538461538461\n",
            "Accuracy of training in KNN is 0.9615384615384616\n",
            "Confusion Matrix:\n",
            "[[ 5  2]\n",
            " [ 4 28]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "# Create DMatrix objects for training and testing\n",
        "dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=Y_test)\n",
        "\n",
        "# Define parameters for XGBoost\n",
        "params = {\n",
        "    'objective': 'binary:logistic',  # Classification task with binary labels\n",
        "    'max_depth': 3,  # Maximum depth of each tree\n",
        "    'eta': 0.1,  # Learning rate\n",
        "    'eval_metric': 'error'  # Evaluation metric\n",
        "}\n",
        "\n",
        "# Training the XGBoost model\n",
        "num_rounds = 100  # Number of boosting rounds (trees)\n",
        "xg_model = xgb.train(params, dtrain, num_rounds)\n",
        "\n",
        "# Making predictions on the testing set\n",
        "xg_test = xg_model.predict(dtest)\n",
        "xg_test = [round(pred) for pred in xg_test]  # Convert probabilities to binary labels\n",
        "\n",
        "# Calculating accuracy\n",
        "accuracy = accuracy_score(Y_test, xg_test)\n",
        "print(\"Accuracy of XGBoost on test:\", accuracy)\n",
        "\n",
        "# Making predictions on the training set\n",
        "xg_train = xg_model.predict(dtrain)\n",
        "xg_train = [round(pred) for pred in xg_train]  # Convert probabilities to binary labels\n",
        "\n",
        "# Calculating accuracy on training set\n",
        "acc = accuracy_score(Y_train, xg_train)\n",
        "print(\"Accuracy of XGBoost on training:\", acc)\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(Y_test, xg_test)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_21DhX6-Ijx",
        "outputId": "48db901e-6570-47ed-aff6-3c200a2bc873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of XGBoost on test: 0.9487179487179487\n",
            "Accuracy of XGBoost on training: 1.0\n",
            "Confusion Matrix:\n",
            "[[ 5  2]\n",
            " [ 0 32]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model evaluation"
      ],
      "metadata": {
        "id": "R_DBuf3SZvUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#taking one random data from our data set and predicting its value  first one is negative and remaiining all are positive\n",
        "data = [\n",
        "    [237.323, 243.709, 229.256, 0.00303, 0.00001, 0.00173, 0.00159, 0.00519, 0.01242, 0.116, 0.00696, 0.00747, 0.00882, 0.02089, 0.00533, 24.679, 0.384868, 0.62671, -7.018057, 0.176316, 1.852402, 0.091604],\n",
        "    [223.361, 263.872, 87.638, 0.00352, 0.00002, 0.00169, 0.00188, 0.00506, 0.02536, 0.225, 0.01379, 0.01478, 0.01909, 0.04137, 0.01493, 20.366, 0.566849, 0.574282, -5.456811, 0.345238, 2.840556, 0.232861],\n",
        "    [169.774,191.759,151.451,0.01568,0.00009,0.00863,0.00946,0.02589,0.08143,0.821,0.03804,0.05426,0.08808,0.11411,0.0753,12.359,0.56161,0.793509,-3.297668,0.414758,3.413649,0.457533],\n",
        "[183.52,216.814,161.34,0.01466,0.00008,0.00849,0.00819,0.02546,0.0605,0.618,0.02865,0.04101,0.06359,0.08595,0.06057,14.367,0.478024,0.768974,-4.276605,0.355736,3.142364,0.336085],\n",
        "[188.62,216.302,165.982,0.01719,0.00009,0.00996,0.01027,0.02987,0.07118,0.722,0.03474,0.0458,0.06824,0.10422,0.08069,12.298,0.55287,0.764036,-3.377325,0.335357,3.274865,0.418646],\n",
        "[202.632,565.74,177.258,0.01627,0.00008,0.00919,0.00963,0.02756,0.0717,0.833,0.03515,0.04265,0.0646,0.10546,0.07889,14.989,0.427627,0.775708,-4.892495,0.262281,2.910213,0.270173],\n",
        "[186.695,211.961,149.442,0.01872,0.0001,0.01075,0.01154,0.03225,0.0583,0.784,0.02699,0.03714,0.06259,0.08096,0.10952,12.529,0.507826,0.762726,-4.484303,0.340256,2.958815,0.301487],\n",
        "[192.818,224.429,168.793,0.03107,0.00016,0.018,0.01958,0.05401,0.11908,1.302,0.05647,0.0794,0.13778,0.16942,0.21713,8.441,0.625866,0.76832,-2.434031,0.450493,3.079221,0.527367],\n",
        "[198.116,233.099,174.478,0.02714,0.00014,0.01568,0.01699,0.04705,0.08684,1.018,0.04284,0.05556,0.08318,0.12851,0.16265,9.449,0.584164,0.754449,-2.839756,0.356224,3.184027,0.454721],\n",
        "]\n",
        "\n",
        "\n",
        "# Use the StandardScaler to transform the input_data\n",
        "std = sc.transform(data)\n",
        "\n",
        "# predicting using trained svm model\n",
        "prediction = x.predict(std)\n",
        "n=0\n",
        "while len(prediction):\n",
        "  if prediction[n]==0:\n",
        "    print(\"Negative\\n\")\n",
        "  else:\n",
        "    print(\"Positive \\n\")\n",
        "  n+=1\n",
        "  if n==len(prediction):\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vheORxhZ4VA",
        "outputId": "3bdba5d4-91da-4ea5-b428-6e6c69884558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative\n",
            "\n",
            "Positive \n",
            "\n",
            "Positive \n",
            "\n",
            "Positive \n",
            "\n",
            "Positive \n",
            "\n",
            "Positive \n",
            "\n",
            "Positive \n",
            "\n",
            "Positive \n",
            "\n",
            "Positive \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Path to the zip file\n",
        "zip_file_path = 'data.zip'\n",
        "\n",
        "# Directory where you want to extract the contents of the zip file\n",
        "extract_to_directory = 'data/'\n",
        "\n",
        "# Open the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Extract all the contents to the specified directory\n",
        "    zip_ref.extractall(extract_to_directory)\n",
        "\n",
        "print(\"Zip file extracted successfully.\")\n"
      ],
      "metadata": {
        "id": "pZOGt6j6nbjP",
        "outputId": "6356b650-0df2-493d-e028-8fada69bc555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file extracted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Function to extract features from text files\n",
        "def extract_features_from_text(text_file):\n",
        "    try:\n",
        "        with open(text_file, 'r') as file:\n",
        "            text = file.read()\n",
        "        feature1 = len(text)\n",
        "        feature2 = text.lower().count('important')  # Convert text to lowercase\n",
        "        return [feature1, feature2]\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing text file '{text_file}': {e}\")\n",
        "        return [None, None]\n",
        "\n",
        "# Function to extract features from images\n",
        "def extract_features_from_image(image_file):\n",
        "    try:\n",
        "        image = Image.open(image_file)\n",
        "        feature1, feature2 = image.size\n",
        "        return [feature1, feature2]\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image '{image_file}': {e}\")\n",
        "        return [None, None]\n",
        "\n",
        "# Load data from text files\n",
        "control_folder = \"data/hw_dataset/control/\"\n",
        "parkinson_folder = \"data/hw_dataset/parkinson/\"\n",
        "\n",
        "control_files = [os.path.join(control_folder, f) for f in os.listdir(control_folder)]\n",
        "parkinson_files = [os.path.join(parkinson_folder, f) for f in os.listdir(parkinson_folder)]\n",
        "\n",
        "control_data = [extract_features_from_text(file) for file in control_files]\n",
        "parkinson_data = [extract_features_from_text(file) for file in parkinson_files]\n",
        "\n",
        "# Create DataFrame from text data\n",
        "control_df = pd.DataFrame(control_data, columns=[\"Text_Feature1\", \"Text_Feature2\"])\n",
        "control_df[\"parkinsons\"] = 0\n",
        "parkinson_df = pd.DataFrame(parkinson_data, columns=[\"Text_Feature1\", \"Text_Feature2\"])\n",
        "parkinson_df[\"parkinsons\"] = 1\n",
        "\n",
        "# Combine control and Parkinson's data\n",
        "merged_df = pd.concat([control_df, parkinson_df], ignore_index=True)\n",
        "\n",
        "# Load data from images\n",
        "dynamic_folder = \"data/hw_drawings/Dynamic Spiral Test/\"\n",
        "static_folder = \"data/hw_drawings/Static Spiral Test/\"\n",
        "\n",
        "dynamic_files = [os.path.join(dynamic_folder, f) for f in os.listdir(dynamic_folder)]\n",
        "static_files = [os.path.join(static_folder, f) for f in os.listdir(static_folder)]\n",
        "\n",
        "dynamic_data = [extract_features_from_image(file) for file in dynamic_files]\n",
        "static_data = [extract_features_from_image(file) for file in static_files]\n",
        "\n",
        "# Combine image features\n",
        "image_features = dynamic_data + static_data\n",
        "\n",
        "# Ensure the number of image features matches the number of rows in the DataFrame\n",
        "if len(image_features) != len(merged_df):\n",
        "    if len(image_features) > len(merged_df):\n",
        "        image_features = image_features[:len(merged_df)]\n",
        "    else:\n",
        "        num_features_to_pad = len(merged_df) - len(image_features)\n",
        "        placeholder_value = [np.nan, np.nan]\n",
        "        image_features += [placeholder_value] * num_features_to_pad\n",
        "\n",
        "# Add image features to DataFrame\n",
        "merged_df[\"Image_Feature1\"] = [feat[0] for feat in image_features]\n",
        "merged_df[\"Image_Feature2\"] = [feat[1] for feat in image_features]\n",
        "\n",
        "# Drop rows with any NaN values\n",
        "merged_df.dropna(inplace=True)\n",
        "\n",
        "# Split features and target variable\n",
        "X = merged_df.drop(columns=[\"parkinsons\"])\n",
        "y = merged_df[\"parkinsons\"]\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define classifiers with tuned hyperparameters\n",
        "svm_clf = SVC(kernel='rbf', C=10, gamma='auto')\n",
        "nb_clf = GaussianNB()\n",
        "log_reg_clf = LogisticRegression(C=1, solver='liblinear')\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {\"SVM\": svm_clf, \"Naive Bayes\": nb_clf, \"Logistic Regression\": log_reg_clf}\n",
        "results = {}\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[name] = accuracy\n",
        "\n",
        "# Print results\n",
        "for name, accuracy in results.items():\n",
        "    print(f\"{name} Accuracy: {accuracy}\")\n",
        "\n",
        "# Choose the best classifier\n",
        "best_classifier = max(results, key=results.get)\n",
        "print(f\"Best Classifier: {best_classifier}\")\n"
      ],
      "metadata": {
        "id": "KQHAo77krc_4",
        "outputId": "c9d7e996-5eb2-483b-936c-c6a13a5f31b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.75\n",
            "Naive Bayes Accuracy: 0.75\n",
            "Logistic Regression Accuracy: 0.75\n",
            "Best Classifier: SVM\n"
          ]
        }
      ]
    }
  ]
}